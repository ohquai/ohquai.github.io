{"meta":{"title":"CTの一方寸土","subtitle":null,"description":null,"author":"奥拉基爾","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2017-12-27T16:53:07.000Z","updated":"2017-12-27T16:53:07.979Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-27T16:53:02.000Z","updated":"2017-12-27T16:53:02.203Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-12-27T16:51:40.000Z","updated":"2017-12-27T16:52:49.227Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"自编码器原理及介绍","date":"2018-01-13T14:38:28.304Z","updated":"2018-01-13T14:38:29.590Z","comments":true,"path":"2018/01/13/自编码器原理及介绍/","link":"","permalink":"http://yoursite.com/2018/01/13/自编码器原理及介绍/","excerpt":"自编码器原理及介绍 title: 自编码器原理及介绍date: 2018-01-13 22:34:09tags: 特征工程 自编码器 引子在我们做机器学习或者数据挖掘过程中，常常会遇见特征维度过多的情况，或者特征意义不明，我们希望能够将现有特征进行整合，形成具有代表性的更精简的特征，这便是我们通常所谓的降维。 传统降维方法一种我们经常听到或使用的方法是：主成分分析法（PCA，Principal Component Analysis），这是一种无监督学习的方法。通过现有的n维特征，将n维特征映射到k维上（k&lt; n），这k维特征通常是全新的正交特征，称为主元，是重新构造出来的k维特征。","text":"自编码器原理及介绍 title: 自编码器原理及介绍date: 2018-01-13 22:34:09tags: 特征工程 自编码器 引子在我们做机器学习或者数据挖掘过程中，常常会遇见特征维度过多的情况，或者特征意义不明，我们希望能够将现有特征进行整合，形成具有代表性的更精简的特征，这便是我们通常所谓的降维。 传统降维方法一种我们经常听到或使用的方法是：主成分分析法（PCA，Principal Component Analysis），这是一种无监督学习的方法。通过现有的n维特征，将n维特征映射到k维上（k&lt; n），这k维特征通常是全新的正交特征，称为主元，是重新构造出来的k维特征。我们一般认为，信号具有较大的方差（包含信息），噪声具有较小的方差。所以我们认为的最好的k个特征应该尽可能的包含有用信号，亦即信号损失尽可能小。故在将n维特征转换为k维后，取的是前k个较大方差的特征方向。而新特征的选择，也就是选择那些方差损失最小的特征。PCA详细信息可参考下面的知乎贴：在做主成分分析（pca）时，选取的主特征是原来数据的哪些特征呢？谁能用通俗易懂的语言讲解一下什么是PCA主成分分析？ 存在问题：它本质上是线性变化。因为新的k维特征矩阵=原始矩阵*特征向量矩阵，实际上对于每一个新特征，其实是原始特征的某种线性变换。因此，对于非线性的特征抽象或者降维，PCA将无能为力。 神经网络与自编码器待续","categories":[],"tags":[]},{"title":"Docker安装基于CentOS的双Python系统流程","slug":"Docker安装基于CentOS的双Python系统流程","date":"2018-01-10T17:07:39.000Z","updated":"2018-01-11T17:18:56.468Z","comments":true,"path":"2018/01/11/Docker安装基于CentOS的双Python系统流程/","link":"","permalink":"http://yoursite.com/2018/01/11/Docker安装基于CentOS的双Python系统流程/","excerpt":"Docker安装基于CentOS的双Python系统流程引子目前docker容器非常火爆，许多公司已经将docker作为开发和生产环境部署的重要环节，docker的学习不可避免。同时，由于家中和公司一共4台电脑+N台服务器，每一台都要配置环境，相当繁琐，docker的功能正好满足我们在不同环境可以轻松进行开发和测试的需求。因此，我将自己学习、安装、应用docker的过程分享出来，以供读者借鉴，少走弯路。测试主要是在Windows10系统上进行，目的是在Docker上创建一个Centos系统，然后安装2.7和3.6两个版本的Python，以便日后的机器学习和深度学习的需求。Docker本身的安装不再赘言，去下载一个docker toolbox目前看来是最快的。在我的windows系统上，不需要安装docker或VM VirtualBox，直接运行docker toolbox即可进入Docker环境。 CentOS环境搭建","text":"Docker安装基于CentOS的双Python系统流程引子目前docker容器非常火爆，许多公司已经将docker作为开发和生产环境部署的重要环节，docker的学习不可避免。同时，由于家中和公司一共4台电脑+N台服务器，每一台都要配置环境，相当繁琐，docker的功能正好满足我们在不同环境可以轻松进行开发和测试的需求。因此，我将自己学习、安装、应用docker的过程分享出来，以供读者借鉴，少走弯路。测试主要是在Windows10系统上进行，目的是在Docker上创建一个Centos系统，然后安装2.7和3.6两个版本的Python，以便日后的机器学习和深度学习的需求。Docker本身的安装不再赘言，去下载一个docker toolbox目前看来是最快的。在我的windows系统上，不需要安装docker或VM VirtualBox，直接运行docker toolbox即可进入Docker环境。 CentOS环境搭建 1. 从docker-cn安装CentOS系统为了更快速pull到image(镜像)，一种是翻墙下，一种是通过国内的镜像下载，这里推荐直接使用docker-cn的镜像。 docker pull registry.docker-cn.com/library/centos 2. 进入容器（Container）内部看一下，并退出 docker run -it registry.docker-cn.com/library/centos bash ctrl-d 3. 创建image这步可以晚点做，但为了使我们调用便捷，我们先创建一个image。377为container id的前三位，一般前三位即已足够。 docker commit 377 server-centos 4. 正式进入CentOS系统 docker run -it risk-ml/centos-python bash 5. 安装必要的包为了进一步的安装，以及之后的步骤减少反复，这里讲大致需要的包先统一安装完。以后如果发现缺了，还需要yum install补充，有些还需要后续的编译和安装才能奏效。 yum install wget gcc make zlib-devel gityum install readline-devel openssl-develyum install bzip2-devel ncurses-devel sqlite-devel gdbm-devel xz-devel tk-devel 选择y继续 6. 下载Python3源码CentOS自带的是Python2.7，Python3以上的版本需要自己安装。在线下载python3.6的压缩包，这个速度到是挺快的。 wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz 7. 解包、解压缩 xz -d Python-3.6.1.tar.xztar -xvf Python-3.6.1.tar 8. 配置 cd Python-3.6.1./configure –prefix=/usr/local/python3.6 –enable-optimizations –prefix 是预期安装目录，–enable-optimizations 是优化选项（LTO，PGO 等）加上这个 flag 编译后，性能有 10% 左右的优化（如果没记错的话），但是这会明显的增加编译时间。 9. 编译、安装 make make install 注意，有时候发现缺少了一些包，在重新yum了之后，需要重新进行configure和make install 10. 命令映射这个步骤是为了以后操作更简便，我们将python3的命令映射到环境变量的path中，可以直接调用，省去了指定路径。同时避免了在同时有python2和python3的环境中的版本指定问题。 ln -s /usr/local/python3.6/bin/python3 /usr/bin/python3ln -s /usr/local/python3.6/bin/pip3 /usr/bin/pip3 当我们需要通过python2运行脚本或安装包时，只需要执行： python script.pypip install pandas 当我们需要通过python3运行脚本或安装包时，只需要执行： python3 script.pypip3 install pandas 至此，Centos内部的环境基本搭建完毕，已经可以使用python了，我们可以通过python –version和python3 –version查看版本号以确认。 Python环境搭建1. python2安装pip因为原装的Python2.7没有pip，我们需要安装一下，具体不再赘述 yum install epel-releaseyum install python-pip 2. python2安装matplotlib这一步放在最前面，是因为碰到了些问题。注意，此处没有用pip安装，而是用yum安装，并且需要预装一些依赖包 yum install freetype freetype-devel python-freetypeyum install libpng libpng-devel python-pypngyum install python-matplotlib 虽然matplotlib已经安装完毕，但还是有一些问题暂时没得到解决。我们import matplotlib没有问题，但是pyplot的调用会引发报错。最简单的解决办法是在使用pyplot的脚本中加上use(‘Agg’)，问题即可解决 import matplotlibmatplotlib.use(‘Agg’)from matplotlib.pyplot import * 3. 安装xgboost在安装xgboost过程中，容易碰到各种问题，特别是安装0.60以上的版本。各种尝试后，最有效的是通过git clone github上的xgboost进行安装。 # 提前安装一些依赖包yum install gcc gcc-c++yum install lapack lapack-devel blas blas-devel # 下载xgboost源码，并编译git clone –recursive https://github.com/dmlc/xgboostcd xgboostgit submodule initgit submodule updatemake -j4 # 到路径下直接进行安装，Python2和Python3都安装一下cd python-package/python setup.py installpython3 setup.py install 4. 安装tensorflow和keras如果在深度学习方面有要求的话，可以顺便装一下keras和tensorflow。整体都没什么问题，中间缺少的依赖包也可以提前装一下 pip install np-utils 其他Docker操作既然要用Docker，一切实用且必要的操作我在这里也简单介绍一下 1. 文件映射当我们在主机上已经有一些脚本或者文件，希望通过Centos中的Python环境去执行或读取。此时，需要将本地的文件夹在远程端做一个同步的映射。 docker run -it -v /home/me/docker/project1:/usr/me/project2 server-centos bash 在本地（或者是服务器）创建文件的存放目录： /home/me/docker/project1 在docker的container中创建同步的目录：/usr/me/project2 通过上面的命令可以做文件夹的映射，执行上面的run命令之后，会运行镜像，并且在CentOS的/usr/me/project2路径下会自动包含所有本地/home/me/docker/project1中的文件。当然，如果中间隔的中间服务器太多，我们还需要先将文件进行传输（复制)，接下来会讲到。 2. 服务器之间的文件传输经常地，我们要在Windows和Linux服务器之间或者两个linux服务器之间进行文件传输，我们分开介绍。 2.1. Windows与Linux服务器之间推荐XFPT，可以直接进行界面化操作，这里不做详细展开。 2.2. Linux服务器之间（有密码） scp -r /home/me/docker/project1 me@xxx.xx.xxx.xx:/usr/me/project2 会将整个project1文件夹拷贝到project2文件夹中，默认是需要输入登录密码的 2.3. Linux服务器之间（无密码）如果希望无密码登录，需要通过ssh传输 server A 进入用户目录： cd /home/me创建.ssh目录： mkdir .ssh进入.ssh目录： cd .ssh生成密钥对： ssh-keygen -b 1024 -t rsa server B 进入用户目录： cd /usr/me创建.ssh目录： mkdir .ssh进入.ssh目录： cd .ssh创建新文件： touch authorized_keys server A Key授权：scp -p .ssh/id_rsa.pub me@xxx.xx.xxx.xx:/usr/me/.ssh/authorized_keys/authorized_keys将A生成的id_rsa.pub放到B上的授权key文件中 server A 无密码传输：scp -r /home/me/docker/project1 me@xxx.xx.xxx.xx:/usr/me/project2 需要注意，因为传输中没有指定key的位置，因此，最后执行scp操作时需要在包含.ssh文件夹的目录下 3. 镜像的保存与转移当我们有一份完整的比较好的镜像，希望可以在别的服务器上使用，通常有两种方式： 上传镜像到仓库中（本地或公共仓库），但是另一台服务器很肯能只是与当前服务器局域网想通而没有公网的，所以如果使用仓库的方式，只能自己搭建私有仓库（private registry） 将镜像保存为文件上传到其他服务器再从文件中载入镜像 具体实现方式如下： # 存储成压缩包 docker save server-centos &gt; /home/me/server-centos.tar # 使用ssh等方法传输文件之后，通过压缩包解压： scp -r /home/me/server-centos.tar me@xxx.xx.xxx.xx:/usr/medocker load &lt; /usr/me/server-centos.tardocker images 作者: 奥拉基爾2018 年 01月 11日 参考目录 [1]: https://segmentfault.com/a/1190000009922582 [2]: http://blog.csdn.net/u011860731/article/details/46534321 [3]: http://blog.csdn.net/dream_angel_z/article/details/46955705 [4]: http://blog.csdn.net/levy_cui/article/details/60573520 [5]: https://github.com/dmlc/xgboost/issues/909 [6]: https://www.cnblogs.com/saolv/p/6963314.html [7]: http://www.linuxidc.com/Linux/2015-01/111894.htm","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"},{"name":"安装流程","slug":"安装流程","permalink":"http://yoursite.com/tags/安装流程/"}]},{"title":"Random-Forest","slug":"Random-Forest","date":"2017-12-27T17:47:34.000Z","updated":"2017-12-27T17:48:47.958Z","comments":true,"path":"2017/12/28/Random-Forest/","link":"","permalink":"http://yoursite.com/2017/12/28/Random-Forest/","excerpt":"","text":"随机森林它通过自助法（bootstrap）重采样技术，从原始训练样本集N中有放回地重复随机抽取k个样本生成新的训练样本集合，然后根据自助样本集生成k个分类树组成随机森林，新数据的分类结果按分类树投票多少形成的分数而定。在生成每棵树的时候，每个节点变量都仅仅在随机选出的少数变量中产生。因此，不但样本是随机的，连每个节点变量（Features）的产生都是随机的。且由于随机性，一般不需要额外做剪枝 优点 在数据集上表现良好，两个随机性的引入，使得随机森林不容易陷入过拟合（样本随机，特征随机） 在当前的很多数据集上，相对其他算法有着很大的优势，两个随机性的引入，使得随机森林具有很好的抗噪声能力 它能够处理很高维度（feature很多）的数据，并且不用做特征选择，对数据集的适应能力强：既能处理离散型数据，也能处理连续型数据，数据集无需规范化 训练速度快，可以得到变量重要性排序 在训练过程中，能够检测到feature间的互相影响 容易做成并行化方法 实现比较简单","categories":[],"tags":[]}]}
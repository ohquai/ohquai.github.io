{"meta":{"title":"CTの一方寸土","subtitle":null,"description":null,"author":"奥拉基爾","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2017-12-27T16:51:40.000Z","updated":"2017-12-27T16:52:49.227Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2017-12-27T16:53:07.000Z","updated":"2017-12-27T16:53:07.979Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-27T16:53:02.000Z","updated":"2017-12-27T16:53:02.203Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"自编码器原理及介绍","slug":"自编码器原理及介绍","date":"2018-01-13T14:34:09.000Z","updated":"2018-01-13T14:40:42.916Z","comments":true,"path":"2018/01/13/自编码器原理及介绍/","link":"","permalink":"http://yoursite.com/2018/01/13/自编码器原理及介绍/","excerpt":"自编码器原理及介绍引子在我们做机器学习或者数据挖掘过程中，常常会遇见特征维度过多的情况，或者特征意义不明，我们希望能够将现有特征进行整合，形成具有代表性的更精简的特征，这便是我们通常所谓的降维。 传统降维方法一种我们经常听到或使用的方法是：主成分分析法（PCA，Principal Component Analysis），这是一种无监督学习的方法。通过现有的n维特征，将n维特征映射到k维上（k&lt; n），这k维特征通常是全新的正交特征，称为主元，是重新构造出来的k维特征。","text":"自编码器原理及介绍引子在我们做机器学习或者数据挖掘过程中，常常会遇见特征维度过多的情况，或者特征意义不明，我们希望能够将现有特征进行整合，形成具有代表性的更精简的特征，这便是我们通常所谓的降维。 传统降维方法一种我们经常听到或使用的方法是：主成分分析法（PCA，Principal Component Analysis），这是一种无监督学习的方法。通过现有的n维特征，将n维特征映射到k维上（k&lt; n），这k维特征通常是全新的正交特征，称为主元，是重新构造出来的k维特征。我们一般认为，信号具有较大的方差（包含信息），噪声具有较小的方差。所以我们认为的最好的k个特征应该尽可能的包含有用信号，亦即信号损失尽可能小。故在将n维特征转换为k维后，取的是前k个较大方差的特征方向。而新特征的选择，也就是选择那些方差损失最小的特征。PCA详细信息可参考下面的知乎贴：在做主成分分析（pca）时，选取的主特征是原来数据的哪些特征呢？谁能用通俗易懂的语言讲解一下什么是PCA主成分分析？ 存在问题：它本质上是线性变化。因为新的k维特征矩阵=原始矩阵*特征向量矩阵，实际上对于每一个新特征，其实是原始特征的某种线性变换。因此，对于非线性的特征抽象或者降维，PCA将无能为力。 神经网络与自编码器待续","categories":[],"tags":[{"name":"特征工程","slug":"特征工程","permalink":"http://yoursite.com/tags/特征工程/"},{"name":"自编码器","slug":"自编码器","permalink":"http://yoursite.com/tags/自编码器/"}]},{"title":"Docker安装基于CentOS的双Python系统流程","slug":"Docker安装基于CentOS的双Python系统流程","date":"2018-01-10T17:07:39.000Z","updated":"2018-01-11T17:18:56.468Z","comments":true,"path":"2018/01/11/Docker安装基于CentOS的双Python系统流程/","link":"","permalink":"http://yoursite.com/2018/01/11/Docker安装基于CentOS的双Python系统流程/","excerpt":"Docker安装基于CentOS的双Python系统流程引子目前docker容器非常火爆，许多公司已经将docker作为开发和生产环境部署的重要环节，docker的学习不可避免。同时，由于家中和公司一共4台电脑+N台服务器，每一台都要配置环境，相当繁琐，docker的功能正好满足我们在不同环境可以轻松进行开发和测试的需求。因此，我将自己学习、安装、应用docker的过程分享出来，以供读者借鉴，少走弯路。测试主要是在Windows10系统上进行，目的是在Docker上创建一个Centos系统，然后安装2.7和3.6两个版本的Python，以便日后的机器学习和深度学习的需求。Docker本身的安装不再赘言，去下载一个docker toolbox目前看来是最快的。在我的windows系统上，不需要安装docker或VM VirtualBox，直接运行docker toolbox即可进入Docker环境。 CentOS环境搭建","text":"Docker安装基于CentOS的双Python系统流程引子目前docker容器非常火爆，许多公司已经将docker作为开发和生产环境部署的重要环节，docker的学习不可避免。同时，由于家中和公司一共4台电脑+N台服务器，每一台都要配置环境，相当繁琐，docker的功能正好满足我们在不同环境可以轻松进行开发和测试的需求。因此，我将自己学习、安装、应用docker的过程分享出来，以供读者借鉴，少走弯路。测试主要是在Windows10系统上进行，目的是在Docker上创建一个Centos系统，然后安装2.7和3.6两个版本的Python，以便日后的机器学习和深度学习的需求。Docker本身的安装不再赘言，去下载一个docker toolbox目前看来是最快的。在我的windows系统上，不需要安装docker或VM VirtualBox，直接运行docker toolbox即可进入Docker环境。 CentOS环境搭建 1. 从docker-cn安装CentOS系统为了更快速pull到image(镜像)，一种是翻墙下，一种是通过国内的镜像下载，这里推荐直接使用docker-cn的镜像。 docker pull registry.docker-cn.com/library/centos 2. 进入容器（Container）内部看一下，并退出 docker run -it registry.docker-cn.com/library/centos bash ctrl-d 3. 创建image这步可以晚点做，但为了使我们调用便捷，我们先创建一个image。377为container id的前三位，一般前三位即已足够。 docker commit 377 server-centos 4. 正式进入CentOS系统 docker run -it risk-ml/centos-python bash 5. 安装必要的包为了进一步的安装，以及之后的步骤减少反复，这里讲大致需要的包先统一安装完。以后如果发现缺了，还需要yum install补充，有些还需要后续的编译和安装才能奏效。 yum install wget gcc make zlib-devel gityum install readline-devel openssl-develyum install bzip2-devel ncurses-devel sqlite-devel gdbm-devel xz-devel tk-devel 选择y继续 6. 下载Python3源码CentOS自带的是Python2.7，Python3以上的版本需要自己安装。在线下载python3.6的压缩包，这个速度到是挺快的。 wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz 7. 解包、解压缩 xz -d Python-3.6.1.tar.xztar -xvf Python-3.6.1.tar 8. 配置 cd Python-3.6.1./configure –prefix=/usr/local/python3.6 –enable-optimizations –prefix 是预期安装目录，–enable-optimizations 是优化选项（LTO，PGO 等）加上这个 flag 编译后，性能有 10% 左右的优化（如果没记错的话），但是这会明显的增加编译时间。 9. 编译、安装 make make install 注意，有时候发现缺少了一些包，在重新yum了之后，需要重新进行configure和make install 10. 命令映射这个步骤是为了以后操作更简便，我们将python3的命令映射到环境变量的path中，可以直接调用，省去了指定路径。同时避免了在同时有python2和python3的环境中的版本指定问题。 ln -s /usr/local/python3.6/bin/python3 /usr/bin/python3ln -s /usr/local/python3.6/bin/pip3 /usr/bin/pip3 当我们需要通过python2运行脚本或安装包时，只需要执行： python script.pypip install pandas 当我们需要通过python3运行脚本或安装包时，只需要执行： python3 script.pypip3 install pandas 至此，Centos内部的环境基本搭建完毕，已经可以使用python了，我们可以通过python –version和python3 –version查看版本号以确认。 Python环境搭建1. python2安装pip因为原装的Python2.7没有pip，我们需要安装一下，具体不再赘述 yum install epel-releaseyum install python-pip 2. python2安装matplotlib这一步放在最前面，是因为碰到了些问题。注意，此处没有用pip安装，而是用yum安装，并且需要预装一些依赖包 yum install freetype freetype-devel python-freetypeyum install libpng libpng-devel python-pypngyum install python-matplotlib 虽然matplotlib已经安装完毕，但还是有一些问题暂时没得到解决。我们import matplotlib没有问题，但是pyplot的调用会引发报错。最简单的解决办法是在使用pyplot的脚本中加上use(‘Agg’)，问题即可解决 import matplotlibmatplotlib.use(‘Agg’)from matplotlib.pyplot import * 3. 安装xgboost在安装xgboost过程中，容易碰到各种问题，特别是安装0.60以上的版本。各种尝试后，最有效的是通过git clone github上的xgboost进行安装。 # 提前安装一些依赖包yum install gcc gcc-c++yum install lapack lapack-devel blas blas-devel # 下载xgboost源码，并编译git clone –recursive https://github.com/dmlc/xgboostcd xgboostgit submodule initgit submodule updatemake -j4 # 到路径下直接进行安装，Python2和Python3都安装一下cd python-package/python setup.py installpython3 setup.py install 4. 安装tensorflow和keras如果在深度学习方面有要求的话，可以顺便装一下keras和tensorflow。整体都没什么问题，中间缺少的依赖包也可以提前装一下 pip install np-utils 其他Docker操作既然要用Docker，一切实用且必要的操作我在这里也简单介绍一下 1. 文件映射当我们在主机上已经有一些脚本或者文件，希望通过Centos中的Python环境去执行或读取。此时，需要将本地的文件夹在远程端做一个同步的映射。 docker run -it -v /home/me/docker/project1:/usr/me/project2 server-centos bash 在本地（或者是服务器）创建文件的存放目录： /home/me/docker/project1 在docker的container中创建同步的目录：/usr/me/project2 通过上面的命令可以做文件夹的映射，执行上面的run命令之后，会运行镜像，并且在CentOS的/usr/me/project2路径下会自动包含所有本地/home/me/docker/project1中的文件。当然，如果中间隔的中间服务器太多，我们还需要先将文件进行传输（复制)，接下来会讲到。 2. 服务器之间的文件传输经常地，我们要在Windows和Linux服务器之间或者两个linux服务器之间进行文件传输，我们分开介绍。 2.1. Windows与Linux服务器之间推荐XFPT，可以直接进行界面化操作，这里不做详细展开。 2.2. Linux服务器之间（有密码） scp -r /home/me/docker/project1 me@xxx.xx.xxx.xx:/usr/me/project2 会将整个project1文件夹拷贝到project2文件夹中，默认是需要输入登录密码的 2.3. Linux服务器之间（无密码）如果希望无密码登录，需要通过ssh传输 server A 进入用户目录： cd /home/me创建.ssh目录： mkdir .ssh进入.ssh目录： cd .ssh生成密钥对： ssh-keygen -b 1024 -t rsa server B 进入用户目录： cd /usr/me创建.ssh目录： mkdir .ssh进入.ssh目录： cd .ssh创建新文件： touch authorized_keys server A Key授权：scp -p .ssh/id_rsa.pub me@xxx.xx.xxx.xx:/usr/me/.ssh/authorized_keys/authorized_keys将A生成的id_rsa.pub放到B上的授权key文件中 server A 无密码传输：scp -r /home/me/docker/project1 me@xxx.xx.xxx.xx:/usr/me/project2 需要注意，因为传输中没有指定key的位置，因此，最后执行scp操作时需要在包含.ssh文件夹的目录下 3. 镜像的保存与转移当我们有一份完整的比较好的镜像，希望可以在别的服务器上使用，通常有两种方式： 上传镜像到仓库中（本地或公共仓库），但是另一台服务器很肯能只是与当前服务器局域网想通而没有公网的，所以如果使用仓库的方式，只能自己搭建私有仓库（private registry） 将镜像保存为文件上传到其他服务器再从文件中载入镜像 具体实现方式如下： # 存储成压缩包 docker save server-centos &gt; /home/me/server-centos.tar # 使用ssh等方法传输文件之后，通过压缩包解压： scp -r /home/me/server-centos.tar me@xxx.xx.xxx.xx:/usr/medocker load &lt; /usr/me/server-centos.tardocker images 作者: 奥拉基爾2018 年 01月 11日 参考目录 [1]: https://segmentfault.com/a/1190000009922582 [2]: http://blog.csdn.net/u011860731/article/details/46534321 [3]: http://blog.csdn.net/dream_angel_z/article/details/46955705 [4]: http://blog.csdn.net/levy_cui/article/details/60573520 [5]: https://github.com/dmlc/xgboost/issues/909 [6]: https://www.cnblogs.com/saolv/p/6963314.html [7]: http://www.linuxidc.com/Linux/2015-01/111894.htm","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"},{"name":"安装流程","slug":"安装流程","permalink":"http://yoursite.com/tags/安装流程/"}]},{"title":"随机森林原理介绍与适用情况","slug":"随机森林原理介绍与适用情况","date":"2017-12-27T17:47:34.000Z","updated":"2018-01-14T14:17:02.135Z","comments":true,"path":"2017/12/28/随机森林原理介绍与适用情况/","link":"","permalink":"http://yoursite.com/2017/12/28/随机森林原理介绍与适用情况/","excerpt":"随机森林原理介绍与适用情况随机森林它通过自助法（bootstrap）重采样技术，从原始训练样本集N中有放回地重复随机抽取k个样本生成新的训练样本集合，然后根据自助样本集生成k个分类树组成随机森林，新数据的分类结果按分类树投票多少形成的分数而定。在生成每棵树的时候，每个节点变量都仅仅在随机选出的少数变量中产生。因此，不但样本是随机的，连每个节点变量（Features）的产生都是随机的。且由于随机性，一般不需要额外做剪枝 优点","text":"随机森林原理介绍与适用情况随机森林它通过自助法（bootstrap）重采样技术，从原始训练样本集N中有放回地重复随机抽取k个样本生成新的训练样本集合，然后根据自助样本集生成k个分类树组成随机森林，新数据的分类结果按分类树投票多少形成的分数而定。在生成每棵树的时候，每个节点变量都仅仅在随机选出的少数变量中产生。因此，不但样本是随机的，连每个节点变量（Features）的产生都是随机的。且由于随机性，一般不需要额外做剪枝 优点 在数据集上表现良好，两个随机性的引入，使得随机森林不容易陷入过拟合（样本随机，特征随机） 在当前的很多数据集上，相对其他算法有着很大的优势，两个随机性的引入，使得随机森林具有很好的抗噪声能力 它能够处理很高维度（feature很多）的数据，并且不用做特征选择，对数据集的适应能力强：既能处理离散型数据，也能处理连续型数据，数据集无需规范化 训练速度快，可以得到变量重要性排序 在训练过程中，能够检测到feature间的互相影响 容易做成并行化方法 实现比较简单 原理介绍待续","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"},{"name":"随机森林","slug":"随机森林","permalink":"http://yoursite.com/tags/随机森林/"}]},{"title":"随机森林原理介绍与适用情况（综述篇）","slug":"随机森林原理介绍与适用情况（综述篇）","date":"2017-12-27T17:47:34.000Z","updated":"2018-01-14T16:05:55.464Z","comments":true,"path":"2017/12/28/随机森林原理介绍与适用情况（综述篇）/","link":"","permalink":"http://yoursite.com/2017/12/28/随机森林原理介绍与适用情况（综述篇）/","excerpt":"随机森林原理介绍与适用情况一句话介绍随机森林是一种集成算法（Embedding Learning），它属于Bagging类型，通过组合多个弱分类器，最终结果通过投票或取均值，使得整体模型的结果具有较高的精确度和泛化性能。其可以取得不错成绩，主要归功于“随机”和“森林”，一个使它具有抗过拟合能力，一个使它更加精准。 Bagging【自助法】它通过自助法（bootstrap）重采样技术，从训练集里面采集固定个数的样本，但是每采集一个样本后，都将样本放回。也就是说，之前采集到的样本在放回后有可能继续被采集到。【OOB】在Bagging的每轮随机采样中，训练集中大约有36.8%的数据没有被采样集采集中。对于这部分没采集到的数据，我们常常称之为袋外数据(Out Of Bag，简称OOB)。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。【随机性】对于我们的Bagging算法，一般会随机采集和训练集样本数N一样个数的样本。这样得到的采样集和训练集样本的个数相同，但是样本内容不同。通过这样的自助法生成k个分类树组成随机森林，且这k个分类树的采样集的数据也不同，做到样本随机性。【随机性】同时，在生成每棵树的时候，每个树选取的特征都仅仅是随机选出的少数特征，一般默认取特征总数m的开方。因此，不但样本是随机的，也保证了特征随机性。【输出】Bagging的集合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对T个弱学习器得到的回归结果进行算术平均得到最终的模型输出。【特点】由于随机性，对于降低模型的方差很有作用，故随机森林一般不需要额外做剪枝，即可以取得较好的泛化能力和抗过拟合能力（Low Variance）。当然对于训练集的拟合程度就会差一些，也就是模型的偏倚会大一些（High Bias），仅仅是相对的。","text":"随机森林原理介绍与适用情况一句话介绍随机森林是一种集成算法（Embedding Learning），它属于Bagging类型，通过组合多个弱分类器，最终结果通过投票或取均值，使得整体模型的结果具有较高的精确度和泛化性能。其可以取得不错成绩，主要归功于“随机”和“森林”，一个使它具有抗过拟合能力，一个使它更加精准。 Bagging【自助法】它通过自助法（bootstrap）重采样技术，从训练集里面采集固定个数的样本，但是每采集一个样本后，都将样本放回。也就是说，之前采集到的样本在放回后有可能继续被采集到。【OOB】在Bagging的每轮随机采样中，训练集中大约有36.8%的数据没有被采样集采集中。对于这部分没采集到的数据，我们常常称之为袋外数据(Out Of Bag，简称OOB)。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。【随机性】对于我们的Bagging算法，一般会随机采集和训练集样本数N一样个数的样本。这样得到的采样集和训练集样本的个数相同，但是样本内容不同。通过这样的自助法生成k个分类树组成随机森林，且这k个分类树的采样集的数据也不同，做到样本随机性。【随机性】同时，在生成每棵树的时候，每个树选取的特征都仅仅是随机选出的少数特征，一般默认取特征总数m的开方。因此，不但样本是随机的，也保证了特征随机性。【输出】Bagging的集合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对T个弱学习器得到的回归结果进行算术平均得到最终的模型输出。【特点】由于随机性，对于降低模型的方差很有作用，故随机森林一般不需要额外做剪枝，即可以取得较好的泛化能力和抗过拟合能力（Low Variance）。当然对于训练集的拟合程度就会差一些，也就是模型的偏倚会大一些（High Bias），仅仅是相对的。 随机森林随机森林(Random Forest，RF）是Bagging算法的一种，其实在介绍完Bagging算法之后，随机森林几乎是呼之欲出的。RF相对于Bagging只是对其中一些细节做了自己的规定和设计，使用了CART决策树作为弱学习器。换句话说，其实我们只是将使用CART决策树作为弱学习器的Bagging方法称为随机森林。 抗过拟合首先，正如Bagging介绍中提到的，每个树选取使用的特征时，都是从全部m个特征中随机产生的，本身已经降低了过拟合的风险和趋势。模型不会被特定的特征值或者特征组合所决定，随机性的增加，将控制模型的拟合能力不会无限提高。第二，与决策树不同，RF对决策树的建立做了改进。对于普通的决策树，我们会在节点上所有的m个样本特征中选择一个最优的特征来做决策树的左右子树划分。但是RF的每个树，其实选用的特征是一部分，在这些少量特征中，选择一个最优的特征来做决策树的左右子树划分，将随机性的效果扩大，进一步增强了模型的泛化能力。假设每棵树选取msub个特征，msub越小，此时模型对于训练集的拟合程度会变差，偏倚增加，但是会泛化能力更强，模型方差减小。msub越大则相反。在实际使用中，一般会将msub的取值作为一个参数，通过开启oob验证或使用交叉验证，不断调整参数以获取一个合适的msub的值。 优点 由于采用了集成算法，本身精度比大多数单个算法要好 在测试集上表现良好，由于两个随机性的引入，使得随机森林不容易陷入过拟合（样本随机，特征随机） 在工业上，由于两个随机性的引入，使得随机森林具有一定的抗噪声能力，对比其他算法具有一定优势 由于树的组合，使得随机森林可以处理非线性数据，本身属于非线性分类（拟合）模型 它能够处理很高维度（feature很多）的数据，并且不用做特征选择，对数据集的适应能力强：既能处理离散型数据，也能处理连续型数据，数据集无需规范化 训练速度快，可以运用在大规模数据集上 可以处理缺省值（单独作为一类），不用额外处理 由于有袋外数据（OOB），可以在模型生成过程中取得真实误差的无偏估计，且不损失训练数据量 在训练过程中，能够检测到feature间的互相影响，且可以得出feature的重要性，具有一定参考意义 由于每棵树可以独立、同时生成，容易做成并行化方法 由于实现简单、精度高、抗过拟合能力强，当面对非线性数据时，适于作为基准模型 未完待续……参考目录 [1]: https://www.cnblogs.com/pinard/p/6156009.html [2]: https://www.cnblogs.com/maybe2030/p/4585705.html","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"},{"name":"随机森林","slug":"随机森林","permalink":"http://yoursite.com/tags/随机森林/"}]}]}